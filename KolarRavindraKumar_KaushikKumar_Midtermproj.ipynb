{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/selenium-3.141.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/selenium-3.141.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: mlxtend in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (1.25.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (2.0.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (1.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (3.7.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing path for datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of available datasets\n",
    "datasets = {\n",
    "        1: 'data/Amazon.csv',  # Amazon\n",
    "        2: 'data/Costco.csv',  # Costco\n",
    "        3: 'data/Levis.csv',  # Levis\n",
    "        4: 'data/Nike.csv',  # Nike\n",
    "        5: 'data/Walmart.csv'   # Walmart\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset and performing preprocessing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from CSV file\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    transactions = df.apply(lambda x: set(x.dropna().astype(str)), axis=1).tolist()  # Ensure all items are strings\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaing data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose a dataset:\n",
      "1. Amazon\n",
      "2. Costco\n",
      "3. Levis\n",
      "4. Nike\n",
      "5. Walmart\n",
      "6. Exit\n",
      "\n",
      "Displaying Items and Transactions for: Nike\n",
      "\n",
      "Loading data from data/Nike.csv\n",
      "Data loaded successfully from data/Nike.csv\n",
      "\n",
      "--- List of Items in All Transactions ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Backpack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fitness Leggings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Headband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jacket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soccer Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Socks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sports Bra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T-Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Water Bottle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- List of Transactions ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item 1</th>\n",
       "      <th>Item 2</th>\n",
       "      <th>Item 3</th>\n",
       "      <th>Item 4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transaction ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Running Shoes</td>\n",
       "      <td>Sports Bra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jacket</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Water Bottle</td>\n",
       "      <td>Soccer Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Headband</td>\n",
       "      <td>Socks</td>\n",
       "      <td>Running Shoes</td>\n",
       "      <td>Fitness Leggings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>Sports Bra</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fitness Leggings</td>\n",
       "      <td>Jacket</td>\n",
       "      <td>Soccer Ball</td>\n",
       "      <td>Headband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Running Shoes</td>\n",
       "      <td>Water Bottle</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sports Bra</td>\n",
       "      <td>Headband</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jacket</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>Water Bottle</td>\n",
       "      <td>Soccer Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fitness Leggings</td>\n",
       "      <td>Socks</td>\n",
       "      <td>Sports Bra</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Running Shoes</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Water Bottle</td>\n",
       "      <td>T-Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Soccer Ball</td>\n",
       "      <td>Fitness Leggings</td>\n",
       "      <td>Jacket</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>Sports Bra</td>\n",
       "      <td>Headband</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Backpack</td>\n",
       "      <td>Water Bottle</td>\n",
       "      <td>Soccer Ball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Headband</td>\n",
       "      <td>Jacket</td>\n",
       "      <td>Running Shoes</td>\n",
       "      <td>T-Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Socks</td>\n",
       "      <td>Sports Bra</td>\n",
       "      <td>Water Bottle</td>\n",
       "      <td>Backpack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fitness Leggings</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>Soccer Ball</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Running Shoes</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Jacket</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Water Bottle</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>Fitness Leggings</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Headband</td>\n",
       "      <td>Running Shoes</td>\n",
       "      <td>Jacket</td>\n",
       "      <td>Soccer Ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Socks</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to load data using pandas\n",
    "def load_data_display(file_path):\n",
    "    try:\n",
    "        # Load the CSV file using pandas\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded successfully from {file_path}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to display items and transactions in table format with borders\n",
    "def display_items_and_transactions(data):\n",
    "    # Combine all item columns into one list for unique items\n",
    "    items = pd.concat([data['Item 1'], data['Item 2'], data['Item 3'], data['Item 4']]).dropna().unique()\n",
    "    \n",
    "    # Create a DataFrame for items\n",
    "    items_df = pd.DataFrame(sorted(items), columns=[\"Items\"])\n",
    "    items_df.index = range(1, len(items_df) + 1)  # Adjust the index to start from 1\n",
    "    print(\"\\n--- List of Items in All Transactions ---\")\n",
    "    \n",
    "    # Display items with borders\n",
    "    display(HTML(items_df.to_html(border=1)))\n",
    "\n",
    "    # Create a DataFrame for transactions\n",
    "    transactions_df = data[['Transaction ID', 'Item 1', 'Item 2', 'Item 3', 'Item 4']].copy()\n",
    "    transactions_df = transactions_df.set_index('Transaction ID')  # Keep the default index for transactions\n",
    "    print(\"\\n--- List of Transactions ---\")\n",
    "    \n",
    "    # Display transactions with borders\n",
    "    display(HTML(transactions_df.to_html(border=1)))\n",
    "\n",
    "list_data = ['Amazon', 'Costco', 'Levis', 'Nike', 'Walmart']\n",
    "\n",
    "# Loop until valid input or exit\n",
    "while True:\n",
    "    print(\"Please choose a dataset:\")\n",
    "    for key, name in zip(datasets.keys(), list_data):\n",
    "        print(f\"{key}. {name}\")\n",
    "    print(\"6. Exit\")  # Option to exit\n",
    "\n",
    "    try:\n",
    "        choice = int(input(\"Enter the number corresponding to the dataset: \"))\n",
    "        if choice == 6:\n",
    "            print(\"Exiting program.\")\n",
    "            break  # Exit the program\n",
    "        elif choice in datasets:\n",
    "            print(f\"\\nDisplaying Items and Transactions for: {list_data[choice-1]}\\n\")\n",
    "            file_path = datasets[choice]\n",
    "            print(f\"Loading data from {file_path}\")\n",
    "            transactions = load_data_display(file_path)\n",
    "            if transactions is not None:\n",
    "                display_items_and_transactions(transactions)  # Display items and transactions in table format\n",
    "                break  # Valid dataset chosen and loaded, exit the loop\n",
    "        else:\n",
    "            print(\"Invalid choice. Please select a valid dataset.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number corresponding to the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brute Force Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1-itemsets for Brute Force\n",
    "def generate_1_itemsets(transactions):\n",
    "    itemset = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            itemset[item] += 1\n",
    "    return {frozenset([item]): count for item, count in itemset.items()}\n",
    "\n",
    "# Generate k-itemsets from (k-1)-itemsets\n",
    "def generate_k_itemsets(prev_itemsets, k):\n",
    "    new_itemsets = set()\n",
    "    prev_itemsets = list(prev_itemsets.keys())\n",
    "    \n",
    "    for i in range(len(prev_itemsets)):\n",
    "        for j in range(i + 1, len(prev_itemsets)):\n",
    "            candidate = prev_itemsets[i] | prev_itemsets[j]\n",
    "            if len(candidate) == k:\n",
    "                new_itemsets.add(candidate)\n",
    "    \n",
    "    return new_itemsets\n",
    "\n",
    "# Count support for itemsets\n",
    "def count_support(transactions, itemsets):\n",
    "    itemset_count = defaultdict(int)\n",
    "    \n",
    "    for transaction in transactions:\n",
    "        for itemset in itemsets:\n",
    "            if itemset.issubset(transaction):\n",
    "                itemset_count[itemset] += 1\n",
    "                \n",
    "    return itemset_count\n",
    "\n",
    "# Generate frequent itemsets for Brute Force\n",
    "def generate_frequent_itemsets(transactions, min_support):\n",
    "    frequent_itemsets = {}\n",
    "    total_transactions = len(transactions)\n",
    "    k = 1\n",
    "\n",
    "    # Generate 1-itemsets\n",
    "    current_itemsets = generate_1_itemsets(transactions)\n",
    "\n",
    "    while current_itemsets:\n",
    "        # Filter itemsets based on min_support\n",
    "        frequent_itemsets_k = {itemset: count for itemset, count in current_itemsets.items() if (count / total_transactions) * 100 >= min_support}\n",
    "        if not frequent_itemsets_k:\n",
    "            break\n",
    "        \n",
    "        # # Print the current k-itemsets and their counts\n",
    "        # print(f\"\\n{k}-itemsets:\")\n",
    "        # for itemset, count in frequent_itemsets_k.items():\n",
    "        #     support = (count / total_transactions) * 100\n",
    "        #     print(f\"Itemset: {set(itemset)}, Count: {count}, Support: {support:.2f}%\")\n",
    "        \n",
    "        frequent_itemsets.update(frequent_itemsets_k)\n",
    "        \n",
    "        # Generate next k-itemsets\n",
    "        k += 1\n",
    "        current_candidates = generate_k_itemsets(frequent_itemsets_k, k)\n",
    "        current_itemsets = count_support(transactions, current_candidates)\n",
    "    \n",
    "    return frequent_itemsets\n",
    "\n",
    "# Generate association rules from frequent itemsets\n",
    "def generate_association_rules(frequent_itemsets, min_confidence, total_transactions):\n",
    "    rules = []\n",
    "    \n",
    "    for itemset, support_count in frequent_itemsets.items():\n",
    "        for i in range(1, len(itemset)):\n",
    "            for antecedent in itertools.combinations(itemset, i):\n",
    "                antecedent = frozenset(antecedent)\n",
    "                consequent = itemset - antecedent\n",
    "                \n",
    "                if consequent:\n",
    "                    confidence = (support_count / frequent_itemsets[antecedent]) * 100\n",
    "                    support = (support_count / total_transactions) * 100\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((antecedent, consequent, support, confidence))\n",
    "    \n",
    "    return rules\n",
    "\n",
    "# Encode transactions to one-hot format\n",
    "def encode_transactions(transactions):\n",
    "    items = sorted(set(item for transaction in transactions for item in transaction))\n",
    "    encoded_df = pd.DataFrame(0, index=range(len(transactions)), columns=items)\n",
    "    \n",
    "    for idx, transaction in enumerate(transactions):\n",
    "        for item in transaction:\n",
    "            encoded_df.at[idx, item] = 1\n",
    "    \n",
    "    return encoded_df\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting and Comparing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform rules into a consistent format for comparison (antecedents, consequents, support, confidence)\n",
    "def format_rules(rule_list, brute_force=False):\n",
    "    formatted_rules = set()\n",
    "    if brute_force:\n",
    "        # Brute force rules already come as tuples (antecedent, consequent, support, confidence)\n",
    "        for antecedent, consequent, support, confidence in rule_list:\n",
    "            formatted_rules.add((frozenset(antecedent), frozenset(consequent), round(support, 2), round(confidence, 2)))\n",
    "    else:\n",
    "        # For Apriori and FP-Growth, rules are in DataFrame format with 'antecedents', 'consequents', 'support', 'confidence'\n",
    "        for _, row in rule_list.iterrows():\n",
    "            formatted_rules.add((frozenset(row['antecedents']), frozenset(row['consequents']), round(row['support'] * 100, 2), round(row['confidence'] * 100, 2)))\n",
    "    return formatted_rules\n",
    "\n",
    "# Function to compare the association rules across algorithms\n",
    "def compare_algorithm_rules(brute_force_rules, apriori_rules, fp_growth_rules):\n",
    "    # Format the rules from each approach\n",
    "    brute_force_set = format_rules(brute_force_rules, brute_force=True)\n",
    "    apriori_set = format_rules(apriori_rules)\n",
    "    fp_growth_set = format_rules(fp_growth_rules)\n",
    "\n",
    "    # Check if all sets of rules are identical\n",
    "    identical_rules = brute_force_set == apriori_set == fp_growth_set\n",
    "\n",
    "    if identical_rules:\n",
    "        print(\"\\nThe algorithms produced exactly the same association rules (matching antecedents, consequents, support, and confidence).\")\n",
    "    else:\n",
    "        print(\"\\nThe algorithms generated differing association rules.\")\n",
    "\n",
    "        # Display specific differences for further analysis\n",
    "        print(\"\\nRules unique to Brute Force:\")\n",
    "        print(brute_force_set - apriori_set - fp_growth_set)\n",
    "        \n",
    "        print(\"\\nRules unique to Apriori:\")\n",
    "        print(apriori_set - brute_force_set - fp_growth_set)\n",
    "        \n",
    "        print(\"\\nRules unique to FP-Growth:\")\n",
    "        print(fp_growth_set - brute_force_set - apriori_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose a dataset:\n",
      "1. Amazon\n",
      "2. Costco\n",
      "3. Levis\n",
      "4. Nike\n",
      "5. Walmart\n",
      "6. Exit\n",
      "Loading data\n",
      "Support =  20.0 %\n",
      "Confidence =  30.0 %\n",
      "\n",
      "Brute Force Results:\n",
      "Rule: {'Smart Speaker'} -> {'Headphones'}, Support: 25.00%, Confidence: 62.50%\n",
      "Rule: {'Headphones'} -> {'Smart Speaker'}, Support: 25.00%, Confidence: 71.43%\n",
      "Rule: {'Yoga Mat'} -> {'Kitchen Mixer'}, Support: 20.00%, Confidence: 50.00%\n",
      "Rule: {'Kitchen Mixer'} -> {'Yoga Mat'}, Support: 20.00%, Confidence: 80.00%\n",
      "Rule: {'Coffee Maker'} -> {'Fitness Tracker'}, Support: 20.00%, Confidence: 66.67%\n",
      "Rule: {'Fitness Tracker'} -> {'Coffee Maker'}, Support: 20.00%, Confidence: 57.14%\n",
      "Rule: {'Wireless Mouse'} -> {'Smart Speaker'}, Support: 30.00%, Confidence: 60.00%\n",
      "Rule: {'Smart Speaker'} -> {'Wireless Mouse'}, Support: 30.00%, Confidence: 75.00%\n",
      "Rule: {'Wireless Mouse'} -> {'Headphones'}, Support: 20.00%, Confidence: 40.00%\n",
      "Rule: {'Headphones'} -> {'Wireless Mouse'}, Support: 20.00%, Confidence: 57.14%\n",
      "Rule: {'Wireless Mouse'} -> {'Smart Speaker', 'Headphones'}, Support: 20.00%, Confidence: 40.00%\n",
      "Rule: {'Smart Speaker'} -> {'Wireless Mouse', 'Headphones'}, Support: 20.00%, Confidence: 50.00%\n",
      "Rule: {'Headphones'} -> {'Wireless Mouse', 'Smart Speaker'}, Support: 20.00%, Confidence: 57.14%\n",
      "Rule: {'Wireless Mouse', 'Smart Speaker'} -> {'Headphones'}, Support: 20.00%, Confidence: 66.67%\n",
      "Rule: {'Wireless Mouse', 'Headphones'} -> {'Smart Speaker'}, Support: 20.00%, Confidence: 100.00%\n",
      "Rule: {'Smart Speaker', 'Headphones'} -> {'Wireless Mouse'}, Support: 20.00%, Confidence: 80.00%\n",
      "\n",
      "Apriori Results:\n",
      "                        antecedents                      consequents  support  \\\n",
      "0                    (Coffee Maker)                (Fitness Tracker)     0.20   \n",
      "1                 (Fitness Tracker)                   (Coffee Maker)     0.20   \n",
      "2                   (Smart Speaker)                     (Headphones)     0.25   \n",
      "3                      (Headphones)                  (Smart Speaker)     0.25   \n",
      "4                  (Wireless Mouse)                     (Headphones)     0.20   \n",
      "5                      (Headphones)                 (Wireless Mouse)     0.20   \n",
      "6                        (Yoga Mat)                  (Kitchen Mixer)     0.20   \n",
      "7                   (Kitchen Mixer)                       (Yoga Mat)     0.20   \n",
      "8                  (Wireless Mouse)                  (Smart Speaker)     0.30   \n",
      "9                   (Smart Speaker)                 (Wireless Mouse)     0.30   \n",
      "10  (Wireless Mouse, Smart Speaker)                     (Headphones)     0.20   \n",
      "11     (Wireless Mouse, Headphones)                  (Smart Speaker)     0.20   \n",
      "12      (Smart Speaker, Headphones)                 (Wireless Mouse)     0.20   \n",
      "13                 (Wireless Mouse)      (Smart Speaker, Headphones)     0.20   \n",
      "14                  (Smart Speaker)     (Wireless Mouse, Headphones)     0.20   \n",
      "15                     (Headphones)  (Wireless Mouse, Smart Speaker)     0.20   \n",
      "\n",
      "    confidence      lift  \n",
      "0     0.666667  1.904762  \n",
      "1     0.571429  1.904762  \n",
      "2     0.625000  1.785714  \n",
      "3     0.714286  1.785714  \n",
      "4     0.400000  1.142857  \n",
      "5     0.571429  1.142857  \n",
      "6     0.500000  2.000000  \n",
      "7     0.800000  2.000000  \n",
      "8     0.600000  1.500000  \n",
      "9     0.750000  1.500000  \n",
      "10    0.666667  1.904762  \n",
      "11    1.000000  2.500000  \n",
      "12    0.800000  1.600000  \n",
      "13    0.400000  1.600000  \n",
      "14    0.500000  2.500000  \n",
      "15    0.571429  1.904762  \n",
      "\n",
      "FP-Growth Results:\n",
      "                        antecedents                      consequents  support  \\\n",
      "0                  (Wireless Mouse)                  (Smart Speaker)     0.30   \n",
      "1                   (Smart Speaker)                 (Wireless Mouse)     0.30   \n",
      "2                   (Smart Speaker)                     (Headphones)     0.25   \n",
      "3                      (Headphones)                  (Smart Speaker)     0.25   \n",
      "4                  (Wireless Mouse)                     (Headphones)     0.20   \n",
      "5                      (Headphones)                 (Wireless Mouse)     0.20   \n",
      "6   (Wireless Mouse, Smart Speaker)                     (Headphones)     0.20   \n",
      "7      (Wireless Mouse, Headphones)                  (Smart Speaker)     0.20   \n",
      "8       (Smart Speaker, Headphones)                 (Wireless Mouse)     0.20   \n",
      "9                  (Wireless Mouse)      (Smart Speaker, Headphones)     0.20   \n",
      "10                  (Smart Speaker)     (Wireless Mouse, Headphones)     0.20   \n",
      "11                     (Headphones)  (Wireless Mouse, Smart Speaker)     0.20   \n",
      "12                       (Yoga Mat)                  (Kitchen Mixer)     0.20   \n",
      "13                  (Kitchen Mixer)                       (Yoga Mat)     0.20   \n",
      "14                   (Coffee Maker)                (Fitness Tracker)     0.20   \n",
      "15                (Fitness Tracker)                   (Coffee Maker)     0.20   \n",
      "\n",
      "    confidence      lift  \n",
      "0     0.600000  1.500000  \n",
      "1     0.750000  1.500000  \n",
      "2     0.625000  1.785714  \n",
      "3     0.714286  1.785714  \n",
      "4     0.400000  1.142857  \n",
      "5     0.571429  1.142857  \n",
      "6     0.666667  1.904762  \n",
      "7     1.000000  2.500000  \n",
      "8     0.800000  1.600000  \n",
      "9     0.400000  1.600000  \n",
      "10    0.500000  2.500000  \n",
      "11    0.571429  1.904762  \n",
      "12    0.500000  2.000000  \n",
      "13    0.800000  2.000000  \n",
      "14    0.666667  1.904762  \n",
      "15    0.571429  1.904762  \n",
      "\n",
      "The algorithms produced exactly the same association rules (matching antecedents, consequents, support, and confidence).\n",
      "\n",
      "Timing Performance:\n",
      "Brute Force Time: 0.0003 seconds\n",
      "Apriori Time: 0.0079 seconds\n",
      "FP-Growth Time: 0.0038 seconds\n",
      "\n",
      "Fastest Algorithm: Brute Force with a time of 0.0003 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assume load_data, generate_frequent_itemsets, generate_association_rules, encode_transactions, apriori, association_rules, and fpgrowth are already defined functions\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Loop until valid input or exit\n",
    "    while True:\n",
    "        print(\"Please choose a dataset:\")\n",
    "        for key, name in zip(datasets.keys(), ['Amazon', 'Costco', 'Levis', 'Nike', 'Walmart']):\n",
    "            print(f\"{key}. {name}\")\n",
    "        print(\"6. Exit\")  # Option to exit\n",
    "\n",
    "        try:\n",
    "            choice = int(input(\"Enter the number corresponding to the dataset: \"))\n",
    "            if choice == 6:\n",
    "                print(\"Exiting program.\")\n",
    "                return  # Exit the program\n",
    "            elif choice in datasets:\n",
    "                file_path = datasets[choice]\n",
    "                print(f\"Loading data\")\n",
    "                transactions = load_data(file_path)\n",
    "                break  # Valid dataset chosen, exit the loop\n",
    "            else:\n",
    "                print(\"Invalid choice. Please select a valid dataset.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number corresponding to the dataset.\")\n",
    "\n",
    "    # Input support and confidence thresholds\n",
    "    min_support = float(input(\"Enter minimum support threshold (0-100): \"))\n",
    "    print(\"Support = \",min_support,\"%\")\n",
    "    min_confidence = float(input(\"Enter minimum confidence threshold (0-100): \"))\n",
    "    print(\"Confidence = \",min_confidence,\"%\")\n",
    "\n",
    "    # Brute Force Approach\n",
    "    start_time = time.time()\n",
    "    frequent_itemsets_bf = generate_frequent_itemsets(transactions, min_support)\n",
    "    total_transactions = len(transactions)\n",
    "    association_rules_bf = generate_association_rules(frequent_itemsets_bf, min_confidence, total_transactions)\n",
    "    brute_force_time = time.time() - start_time\n",
    "\n",
    "    # Apriori Approach\n",
    "    start_time = time.time()\n",
    "    encoded_df = encode_transactions(transactions)\n",
    "    frequent_itemsets_apriori = apriori(encoded_df, min_support=min_support / 100, use_colnames=True)\n",
    "    rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=min_confidence / 100)\n",
    "    apriori_time = time.time() - start_time\n",
    "\n",
    "    # FP-Growth Approach\n",
    "    start_time = time.time()\n",
    "    frequent_itemsets_fp = fpgrowth(encoded_df, min_support=min_support / 100, use_colnames=True)\n",
    "    rules_fp = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=min_confidence / 100)\n",
    "    fp_growth_time = time.time() - start_time\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nBrute Force Results:\")\n",
    "    for antecedent, consequent, support, confidence in association_rules_bf:\n",
    "        print(f\"Rule: {set(antecedent)} -> {set(consequent)}, Support: {support:.2f}%, Confidence: {confidence:.2f}%\")\n",
    "\n",
    "    print(\"\\nApriori Results:\")\n",
    "    print(rules_apriori[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "    print(\"\\nFP-Growth Results:\")\n",
    "    print(rules_fp[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "    # Comparison of results (calling the comparison function)\n",
    "    compare_algorithm_rules(association_rules_bf, rules_apriori, rules_fp)\n",
    "\n",
    "\n",
    "    # Timing performance\n",
    "    print(f\"\\nTiming Performance:\")\n",
    "    print(f\"Brute Force Time: {brute_force_time:.4f} seconds\")\n",
    "    print(f\"Apriori Time: {apriori_time:.4f} seconds\")\n",
    "    print(f\"FP-Growth Time: {fp_growth_time:.4f} seconds\")\n",
    "\n",
    "    # Determine which algorithm is fastest\n",
    "    fastest = min((\"Brute Force\", brute_force_time), (\"Apriori\", apriori_time), (\"FP-Growth\", fp_growth_time), key=lambda x: x[1])\n",
    "    print(f\"\\nFastest Algorithm: {fastest[0]} with a time of {fastest[1]:.4f} seconds\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
